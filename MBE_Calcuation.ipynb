{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongUgKim/gender_bias_in_nlp/blob/main/MBE_Calcuation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBDJX55PmMEx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import difflib\n",
        "import nltk\n",
        "import regex as re\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XAykwrc6rM1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563eee78-0d25-4506-9c24-2d3e8284900d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "P-_46gHzm4YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "LAhV3V51m7Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tokenizer_and_model(lang):\n",
        "    if lang == 'de':\n",
        "        model_name = 'deepset/gbert-base'\n",
        "    elif lang == 'es':\n",
        "        model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
        "    elif lang == 'pt':\n",
        "        model_name = 'neuralmind/bert-base-portuguese-cased'\n",
        "    elif lang == 'en':\n",
        "        model_name = 'bert-base-cased'\n",
        "    elif lang == 'zh':\n",
        "        model_name = 'hfl/chinese-bert-wwm-ext'\n",
        "\n",
        "    model = AutoModelForMaskedLM.from_pretrained(model_name, output_hidden_states=True, output_attentions=True)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "        model.to('cuda')\n",
        "    return tokenizer, model"
      ],
      "metadata": {
        "id": "A6gmX9y6nDEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_list(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        n_list = pickle.load(f, encoding='utf8')\n",
        "        return n_list"
      ],
      "metadata": {
        "id": "wyclwBX1pkMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_aul(model, token_ids, log_softmax, attention):\n",
        "    output = model(token_ids)\n",
        "    logits = output.logits.squeeze(0)\n",
        "    log_probs = log_softmax(logits)\n",
        "    token_ids = token_ids.view(-1, 1).detach()\n",
        "    token_log_probs = log_probs.gather(1, token_ids)[1:-1]\n",
        "    if attention:\n",
        "        attentions = torch.mean(torch.cat(output.attentions, 0), 0)\n",
        "        averaged_attentions = torch.mean(attentions, 0)\n",
        "        averaged_token_attentions = torch.mean(averaged_attentions, 0)\n",
        "        token_log_probs = token_log_probs.squeeze(1) * averaged_token_attentions[1:-1]\n",
        "    sentence_log_prob = torch.mean(token_log_probs)\n",
        "    score = sentence_log_prob.item()\n",
        "    return score"
      ],
      "metadata": {
        "id": "GPogQY_Mn4Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mbe(lang, male_filepath, female_filepath, male_list, female_list):\n",
        "    tokenizer, model = load_tokenizer_and_model(lang)\n",
        "    total_score = 0\n",
        "    stereo_score = 0\n",
        "    if torch.cuda.is_available():\n",
        "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    masked_id = tokenizer.mask_token_id\n",
        "    log_softmax = torch.nn.LogSoftmax(dim=1)\n",
        "    male = read_list(male_filepath) if male_filepath is not None else male_list\n",
        "    female = read_list(female_filepath) if female_filepath is not None else female_list\n",
        "    male_inputs = [tokenizer.encode(sentence, return_tensors='pt') for sentence in male]\n",
        "    female_inputs = [tokenizer.encode(sentence, return_tensors='pt') for sentence in female]\n",
        "    attention = True\n",
        "    female_scores = []\n",
        "    male_scores = []\n",
        "\n",
        "    for female_tokens in female_inputs:\n",
        "        with torch.no_grad():\n",
        "            female_score = calculate_aul(model, female_tokens, log_softmax, attention)\n",
        "            female_scores.append(female_score)\n",
        "    for male_tokens in male_inputs:\n",
        "        with torch.no_grad():\n",
        "            male_score = calculate_aul(model, male_tokens, log_softmax, attention)\n",
        "            male_scores.append(male_score)\n",
        "\n",
        "    female_scores = np.array(female_scores)\n",
        "    male_scores = np.array(male_scores)\n",
        "    bias_scores = male_scores > female_scores\n",
        "    biasRating = np.sum(bias_scores).item()\n",
        "    total_sentences = (bias_scores.shape[0])\n",
        "    MBE = biasRating / total_sentences\n",
        "    return round(MBE * 100, 2)"
      ],
      "metadata": {
        "id": "YkecYzlZosac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_sim(v1, v2):\n",
        "  return np.dot(v1,v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "metadata": {
        "id": "a-oGTjcyA0WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_aul_kaneko(model, token_ids, log_softmax, attention):\n",
        "  output = model(token_ids)\n",
        "  logits = output.logits.squeeze(0)\n",
        "  log_probs = log_softmax(logits)\n",
        "  token_ids = token_ids.view(-1,1).detach()\n",
        "  token_log_probs = log_probs.gather(1, token_ids)[1:-1]\n",
        "  if attention:\n",
        "      attentions = torch.mean(torch.cat(output.attentions, 0), 0)\n",
        "      averaged_attentions = torch.mean(attentions, 0)\n",
        "      averaged_token_attentions = torch.mean(averaged_attentions, 0)\n",
        "      token_log_probs = token_log_probs.squeeze(1) * averaged_token_attentions[1:-1]\n",
        "  sentence_log_prob = torch.mean(token_log_probs)\n",
        "  score = sentence_log_prob.item()\n",
        "  hidden_states = output.hidden_states[-1][:,1:-1]\n",
        "  hidden_state = torch.mean(hidden_states, 1).detach().cpu().numpy()\n",
        "  return score, hidden_state\n"
      ],
      "metadata": {
        "id": "HZfWNxo59Uc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mbe_kaneko(lang, male_filepath, female_filepath, male_list, female_list):\n",
        "    if lang == 'de':\n",
        "        model_name = 'deepset/gbert-base'\n",
        "    elif lang == 'es':\n",
        "        model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
        "    elif lang == 'pt':\n",
        "        model_name = 'neuralmind/bert-base-portuguese-cased'\n",
        "    elif lang == 'en':\n",
        "        model_name = 'bert-base-cased'\n",
        "    elif lang == 'zh':\n",
        "        model_name = 'hfl/chinese-bert-wwm-ext'\n",
        "    tokenizer, model = load_tokenizer_and_model(lang)\n",
        "    total_score = 0\n",
        "    stereo_score = 0\n",
        "    tokenizer2 = BertTokenizer.from_pretrained(model_name)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    masked_id = tokenizer.mask_token_id\n",
        "    log_softmax = torch.nn.LogSoftmax(dim=1)\n",
        "    male = read_list(male_filepath) if male_filepath is not None else male_list\n",
        "    female = read_list(female_filepath) if female_filepath is not None else female_list\n",
        "    male_inputs = [tokenizer.encode(sentence, return_tensors='pt') for sentence in male if len(tokenizer2.tokenize(sentence)) < 512]\n",
        "    female_inputs = [tokenizer.encode(sentence, return_tensors='pt') for sentence in female if len(tokenizer2.tokenize(sentence)) < 512]\n",
        "    attention = True\n",
        "    female_scores = []\n",
        "    male_scores = []\n",
        "    female_embes = []\n",
        "    male_embes = []\n",
        "\n",
        "    for female_tokens in female_inputs:\n",
        "        with torch.no_grad():\n",
        "            female_score, female_hidden_state = calculate_aul_kaneko(model, female_tokens, log_softmax, attention)\n",
        "            female_scores.append(female_score)\n",
        "            female_embes.append(female_hidden_state)\n",
        "    for male_tokens in male_inputs:\n",
        "        with torch.no_grad():\n",
        "            male_score, male_hidden_state = calculate_aul_kaneko(model, male_tokens, log_softmax, attention)\n",
        "            male_scores.append(male_score)\n",
        "            male_embes.append(male_hidden_state)\n",
        "\n",
        "    female_scores = np.array(female_scores)\n",
        "    female_scores = female_scores.reshape([-1,1])\n",
        "    male_scores = np.array(male_scores)\n",
        "    male_scores = male_scores.reshape([-1,1])\n",
        "    if len(male_scores) > len(female_scores):\n",
        "      male_scores = male_scores[0:len(female_scores)]\n",
        "    else:\n",
        "      female_scores = female_scores[0:len(male_scores)]\n",
        "    bias_scores = male_scores > female_scores\n",
        "    female_embes = np.concatenate(female_embes)\n",
        "    male_embes = np.concatenate(male_embes)\n",
        "    weights = cos_sim(female_embes, male_embes.T)\n",
        "    weighted_bias_scores = bias_scores * weights\n",
        "    MBE = np.sum(weighted_bias_scores) / np.sum(weights)\n",
        "    return round(MBE * 100, 2)"
      ],
      "metadata": {
        "id": "wTLqTdlJ_1nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "-5qvcoOXsaPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(lang, filepath):\n",
        "    if lang == 'de':\n",
        "        model = 'deepset/gbert-base'\n",
        "    elif lang == 'es':\n",
        "        model = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
        "    elif lang == 'pt':\n",
        "        model = 'neuralmind/bert-base-portuguese-cased'\n",
        "    elif lang == 'en':\n",
        "        model = 'bert-base-cased'\n",
        "    elif lang == 'zh':\n",
        "        model = 'hfl/chinese-bert-wwm-ext'\n",
        "\n",
        "    orignial_list = read_list(filepath)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model)\n",
        "    result = [sentence for sentence in orignial_list if len(tokenizer.tokenize(sentence)) < 512]\n",
        "    return result"
      ],
      "metadata": {
        "id": "NuNbOslHrIJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mbe('de', None, None, rule_male_de, rule_female_de)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8gATKVOQp25",
        "outputId": "373a1ac9-fb37-4928-9473-4dd3c4cb6390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48.64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}